#!/bin/sh

# TODO
# WGET options. Test --warc-max-size=NUMBER
# --warc-file=FILENAME enables the WARC export. WARC files will be based on FILENAME: FILENAME-00000.warc.gz, FILENAME-00001.warc.gz et cetera.
# --warc-max-size=NUMBER defines the maximum size of the WARC files. The default is an infinite limit ("inf"). If you download a large site, the recommended limit is 1GB, set the option to 1G to enable this limit. Note that this is a soft limit: files can get slightly larger than this, depending on the files you download.
# --warc-header=STRING adds STRING as a custom header to the warcinfo record, e.g. "operator: Archive Team". This option can be used multiple times.
# --warc-cdx=FILENAME writes a CDX index file to FILENAME.cdx. The CDX file will contain a list of the records and their locations in the WARC files.
# --warc-dedup=FILENAME can be used to reduce the size of WARC files generated by a recrawl. FILENAME should point to a CDX file, generated with --warc-cdx in a previous run. For each file it downloads, Wget will check the CDX file to see if the response is listed there. If the exact file already exists, a "revisit" record with a reference to the previous record will be added to the WARC file, instead of a duplicate "response" record. Duplicate records are detected by comparing the SHA-1 digest of the payload of the response.
# --no-warc-compression will write uncompressed WARC files. Compression is enabled by default. It is better to use the built-in compression than to compress the WARC files afterwards. The built-in compression will compress each record as an individual GZIP block, which allows other utilities to extract single records from the file.
# --no-warc-digests disables the SHA-1 digests. By default, SHA-1 digests will be calculated for the whole response block and the response payload. If you really need to, you can disable that.
# --no-warc-keep-log can be set if you don't want the Wget log in the WARC file. By default, Wget will add the log file as a separate record to the WARC file.
# --warc-tempdir=DIRECTORY sets the temporary directory used by the WARC writer. The system tempdir will be used by default. 






function create_warcs_concurrently()
{
    echo "CREATE WARCS CONCURRENTLY"
    echo "========================="
    # cd $warcs_work_area_dir
    cd $warcs_dir

    echo "Physical destination warcs dir: "$dest_warcs_dir
    echo "Running $concurrent_warc_jobs CONCURRENT warc jobs for $warcs_parallel_input_file"


    #  Non riesco a lavorare direttamente con $repositories_file (non gestisce break quando incontro "@")
    if [ -f $warcs_parallel_input_file ]; then
        echo "Remove old "$warcs_parallel_input_file
        rm $warcs_parallel_input_file
    fi
    echo "Prepariamo $warcs_parallel_input_file"
    while IFS='|' read -r -a array line
    do
           line=${array[0]}

        # Remove whitespaces (empty lines)
        line=`echo $line | xargs`

        if [[ ${line:0:1} == "@" ]]; then # Ignore rest of file
            break
        fi

           # se riga comentata o vuota skip
           if [[ ${line:0:1} == "#" ]] || [[ ${line} == "" ]];  then
                 continue
            fi

        local istituto=${array[1]}
        local seeds_filename=$seeds_dir"/"$harvest_date_materiale"_"$istituto".seeds"

        echo $seeds_filename >> $warcs_parallel_input_file

    done < $HARVEST_DIR/$repositories_file





        while IFS= read -r seeds_filename
        # while IFS= read -r string
            do
            (
                ((line_ctr++))

                if [[ ${seeds_filename:0:1} == "#" ]] || [[ ${seeds_filename} == "" ]];  then
                    # echo "continue"
                      continue
                fi

               # echo "line_ctr= $line_ctr"
               check_free_disk

               # cd $warcs_work_area_dir

               local fname=$(basename -- "$seeds_filename")
               # local fname="${fname%.*}"


               # if [ "$DEVELOPMENT" == "true" ]; then
               #     local fname="${fname%.*.*}"
               # else
                   local fname="${fname%.*}"
               # fi

 # echo "-->fname=$fname"

                echo "wget_ting $seeds_filename"

               # Option --delete-after instructs wget to delete each downloaded file immediately after its download is complete.
               # Option --no-directories prevents wget from leaving behind a useless tree of empty directories.
               #  Certe opzioni sembrano essere ignorate: eg. --no-directories --no-warc-keep-log
               wget_options="--warc-tempdir=. --delete-after --no-directories --no-warc-keep-log --no-check-certificate --user-agent='bncf' --page-requisites"

# Attivazione file segmentati
wget_options="${wget_options} --warc-max-size=$warc_max_size"

                # DEBUG
               # wget_options="--warc-tempdir=. --no-warc-keep-log --no-check-certificate --user-agent='bncf' --page-requisites"
# pwd
 # echo "wget $wget_options --input-file=$seeds_filename --output-file=./$fname.log --warc-file=./$fname"
                # if  [[ $fname == *unicatt ]] ; # se finisce in unicatt
                # then
                # SEMBRA FUNZIONARE anche solo con controllo indirizzo IP
                #     echo "ACCESSO controllato a pagine dietro login di UNICATT"
                #
                #     echo "Login. Per prendere la sessione utente"
                #     wget --save-cookies cookies.txt --keep-session-cookies --delete-after --post-data 'user=appsrv.docta.ssows&password=kMcydyT3QhqMhlQE4O1m!' https://login.unicatt.it/iam-fe/sso/login
                #
                #     echo "Accesso a pagina di una tesi. Altrimenti non funziona"
                #     wget -qO- --load-cookies ./cookies.txt http://hdl.handle.net/10280/296 &> /dev/null
                #
                #     # 20/02/2020 Depositiamo direttamente il warc file nella cartella dei warc della wayback machine
                #
                #     wget $wget_options --load-cookies ./cookies.txt --input-file=$seeds_filename --output-file=./$fname.log --warc-file=$dest_warcs_dir/$fname
                # fi


                # 26/09/2020 mail Ing. Stefano De Vecchi de 22/09
                if  [[ $fname == *unive ]] ; # se finisce in unicatt
                then
                    echo "ACCESSO controllato a pagine dietro login di UNIVE"
                    # Ing. Stefano De Vecchi
                    echo "Login. Per prendere la sessione utente"
                    #wget --save-cookies cookies.txt --keep-session-cookies --delete-after --post-data 'username=depositolegale&ldap_password=!W3qmt7SWYA!@pV5' http://dspace.unive.it/ldap-login
                    # echo "HARVEST_UNIVE_PWD="$HARVEST_UNIVE_PWD
                    wget --save-cookies cookies.txt --keep-session-cookies --delete-after --post-data 'username=depositolegale&ldap_password='$HARVEST_UNIVE_PWD http://dspace.unive.it/ldap-login

# wget --load-cookies cookies.txt    http://dspace.unive.it/bitstream/10579/5607/2/986552-1166862.pdf
# wget --load-cookies cookies.txt    http://dspace.unive.it/bitstream/handle/10579/15582/826599-1207989.pdf
# wget --load-cookies cookies.txt    http://dspace.unive.it/bitstream/10579/14975/2/840453-1207992.pdf

                    # if [ $materiale == $MATERIALE_EJOURNAL ]; then
                    #     # 25/01/2021 Cerchiamo di scaricare worker.js et al (Call con Storti)
                    #     # ‘-r’
                    #     # ‘--recursive’ Turn on recursive retrieving. See Recursive Download, for more details. The default maximum depth is 5.
                            
                    #     # ‘-l depth’
                    #     # ‘--level=depth’                        

                    #     wget_options="${wget_options} --recursive --level=5"
                    # fi


                    wget $wget_options --load-cookies ./cookies.txt --input-file=$seeds_filename --output-file=./$fname.log --warc-file=$warcs_dir/$fname
                else
                    # Scarico standard

                    # 20/02/2020 Depositiamo direttamente il warc file nella cartella dei warc della wayback machine
                    # wget $wget_options --input-file=$seeds_filename --output-file=./$fname.log --warc-file=$dest_warcs_dir/$fname

# gestito in fase di estrazione seeds
                    # if [ $materiale == $MATERIALE_EJOURNAL ]; then
                    #     wget_options="${wget_options} --lua-script=$HARVEST_DIR/scripts/ojs.lua"
                    # fi

# echo "wget option="$wget_options
# echo "fname="$fname
                    wget $wget_options --input-file=$seeds_filename --output-file=./$fname.log --warc-file=$warcs_dir/$fname


                fi


               ) &
               # allow only to execute $N jobs in parallel
               if [[ $(jobs -r -p | wc -l) -gt $concurrent_warc_jobs ]]; then
                   # wait only for first job
                   wait -n
               fi

            done < "$warcs_parallel_input_file"

            # wait for pending jobs
            wait


        # if [ $materiale == $MATERIALE_EJOURNAL ]; then
        #     # Rinominiamo i warc.gz in $warc_filename.org
        #     while IFS='|' read -r -a array line
        #     do
        #            line=${array[0]}

        #         # Remove whitespaces (empty lines)
        #         line=`echo $line | xargs`

        #         if [[ ${line:0:1} == "@" ]]; then # Ignore rest of file
        #             break
        #         fi

        #            # se riga comentata o vuota skip
        #            if [[ ${line:0:1} == "#" ]] || [[ ${line} == "" ]];  then
        #                  continue
        #             fi

        #         local istituto=${array[1]}
        #         local warc_filename=$warcs_dir"/"$harvest_date_materiale"_"$istituto".warc.gz"

        #         echo "warc_filename="$warc_filename
        #         if [ -f $warc_filename ]; then
        #             echo "rename $warc_filename in "$warc_filename".org"
        #            mv $warc_filename $warc_filename".org"
        #         else
        #             echo "$warc_filename not found to rename"
        #         fi

        #     done < $HARVEST_DIR/$repositories_file

        # fi




cd $HARVEST_DIR

} # end create_warcs_concurrently

function printarr()
{
    # echo "printarr"
    declare -n __p="$1";
    for k in "${!__p[@]}"; do
        printf "%s=%s\n" "$k" "${__p[$k]}"
    done
    # echo "end printarr"
} # End printarr






function check_for_missing_seeds_istituto()
{
    local fname=$1
# echo "fname="$fname

#     # for seeds_to_harvest_filename in $seeds_dir/*.seeds
#     for log_filename in $warcs_log_dir/*.log
#     do
#         fname=$(basename -- "$log_filename")
#         fname="${fname%.*}"

# echo "fname="$fname
# return

        seeds_to_harvest_filename=$seeds_dir/$fname.seeds
        echo "seeds_to_harvest_filename="$seeds_to_harvest_filename
# continue
        # -s FILE - True if the FILE exists and has nonzero size.
        if [[ ! -s $seeds_to_harvest_filename ]]; then
            echo "empty file"
            continue
        fi

        if [ -f $warcs_log_dir/$fname.seeds.missing ]; then
            rm $warcs_log_dir/$fname.seeds.missing
        fi

        declare -A seeds_scaricati_e_non_kv_AR

        # carichiamo i seed finiti nel warc
        siw=$warcs_log_dir"/"$fname.log.seeds_in_warc
        if [[ -f $siw ]]; then
# echo "reading $warcs_log_dir/$fname.log.seeds_in_warc"
            while IFS='|' read -r  line
            do
                tmp=$(sed 's\.*//\\ g' <<<"$line")
                tmp2=${tmp//\+/ }
                url=$(urldecode "$tmp2")
# echo "--->url = $url"
                seeds_scaricati_e_non_kv_AR[$url]="dummy value"
            done < $siw
        fi
# return
        # mettiamo i seed non scaricati nel warc
        sniw=$warcs_log_dir"/"$fname".log.seeds_not_in_warc"
        if [ -s $sniw ]; then
# echo "reading $warcs_log_dir/$fname.log.seeds_not_in_warc"
            while IFS='|' read -r  line
            do
                [ -z "$line" ] && continue  # test empty line
    # echo "line=$line"
                tmp=$(sed 's\.*//\\ g' <<<"$line")
                tmp2=${tmp//\+/ }
                url=$(urldecode "$tmp2")
    # echo "--->url = $url"
                seeds_scaricati_e_non_kv_AR[$url]="dummy value"
            done < $sniw
        fi

# printarr seeds_scaricati_e_non_kv_AR
# return

        # Troviamo i seeds da scaricare non intercettati
        if [[ -f $warcs_log_dir/$fname.log.seeds.missing ]]; then
# echo "Removing $warcs_log_dir/$fname.log.seeds.missing"
            rm $warcs_log_dir/$fname.log.seeds.missing
        fi
# echo "Troviamo i seeds da scaricare non intercettati"
        while IFS= read -r line
            do
    # echo "===>$line"
                tmp=$(sed 's\.*//\\ g' <<<"$line")
                tmp2=$(urldecode "$tmp")
                tmp3=$(urldecode "$tmp2")
                url=${tmp3//\+/ }
                
                if [ -z "$url" ]
                then
                      # echo "\$var is empty"
                      continue
                fi
    # echo "test --->url='$url'"
                if ! test "${seeds_scaricati_e_non_kv_AR[$url]+isset}"
                then
                    echo "$url" >> $warcs_log_dir/$fname.log.seeds.missing
                fi
                # break;
        done < $seeds_to_harvest_filename
    # done # end ciclo sui log
} # end _check_for_missing_seeds_istituto


function check_for_missing_seeds()
{
    echo "CHECK FOR MISSING SEEDS (.missing)"
    echo "=================================="



    DONE=false
    until $DONE; do
        IFS='|' read -r -a array line  || DONE=true

        line=${array[0]}
        # Remove whitespaces (empty lines)
        line=`echo $line | xargs`

        if [[ ${line:0:1} == "@" ]]; then # Ignore rest of file
            break
        fi

        # se riga comentata o vuota skip
        if [[ ${line:0:1} == "#" ]] || [[ ${line} == "" ]];  then
              continue
         fi
        local istituto=${array[1]}

        echo "Working on: " $istituto

        if [ $materiale == $MATERIALE_TESI ]; then
            # Prepariamop le ricevute in formato excel per TESI
    
            check_for_missing_seeds_istituto $harvest_date_materiale"_"$istituto

        elif [ $materiale == $MATERIALE_EJOURNAL ]; then
            # Prepariamop le ricevute in formato excel per E-JOURNALS
            check_for_missing_seeds_istituto $harvest_date_materiale"_"$istituto
        fi

    done < "$repositories_file"
} # end check_for_missing_seeds



# su imtlucca ho avuto un abbattimento dell'indice del 94%
function clean_wayback_index ()
{
    echo "CLEAN WAYBACK INDEX"
    echo "==================="

    # Remove all noise links. eg links to images, javascript, stylesheet, etc.
    # awk '!/\.gif|\.js|\.png|\.css|\.ico|password\-login|robots.txt/' $WAYBACK_INDEX_DIR"/index.cdxj"  > $WAYBACK_INDEX_DIR"/index.cdxj.clean"

    # In bash, you can set the nullglob option so that a pattern that matches nothing "disappears",
    # rather than treated as a literal string
#    shopt -s nullglob
    for filename in $WAYBACK_INDEX_DIR/*cdxj; do
        cd $WAYBACK_INDEX_DIR
        echo "filename="$filename

        # 27/01/2020
        # Remove all noise links. eg links to images, javascript, stylesheet, etc.
        echo "--> cleaning $filename"
        awk '!/\.gif|\.js|\.png|\.css|\.ico|password\-login|robots.txt/' $filename  > $filename.clean

    done
    cd $HARVEST_DIR

} # end clean_wayback_index


function get_indexes_for_compression ()
{

    echo "--> Prendiamo i nuovi indici (cdxj) da :" $WAYBACK_INDEX_DIR " e mettiamoli in " $INDEX_COMPRESSION_DIR"/cdx"

    cd $INDEX_COMPRESSION_DIR
    cp $WAYBACK_INDEX_DIR/*.cdxj "cdx/."

    cd $HARVEST_DIR
}



function compress_warc_indexes ()
{
	completo=$1

    echo "--> Compressione degli indici"
    echo "INDEX_COMPRESSION_DIR: "$INDEX_COMPRESSION_DIR
    cd $INDEX_COMPRESSION_DIR

	if [ $completo == "1" ]; then
		echo "Getting embargoed indexes"
		cp cdx_embargo/*.cdxj cdx/.
	else
		echo "Removing embargoed indexes"
		rm cdx/*embargo*
	fi


    echo "Pulisco la cartella './zipnum'"
    rm ./zipnum/*

    echo "Creo indici compressi in 'zipnum'"
    python build_local_zipnum.py -p ./zipnum/ ./cdx

	# Siccome non ci deve stare zipnum/ lo dobbiamo rimuovere dal file ./zipnum/cluster.loc
	# cdx-00000.gz    ./zipnum/cdx-00000.gz

	echo "Clean ./zipnum/cluster.loc"
	sed -i 's/\.\/zipnum/\./g' ./zipnum/cluster.loc

    cd $HARVEST_DIR
}



function replace_warc_indexes_with_compressed_ones_in_memoria()
{
	echo ""
    echo "--> Sostituisco i vecchi indici (compressi e non) con i nuovi indici compressi per collezione 'memoria.depositolegale.it'"
    cd $INDEX_COMPRESSION_DIR

    if [ ! -d $WAYBACK_INDEX_DIR"/tmp" ]; then
      echo "---> Create directory "$WAYBACK_INDEX_DIR"/tmp"
      mkdir $WAYBACK_INDEX_DIR"/tmp"
	fi



	echo "Sposto gli indici vecchi in "$WAYBACK_INDEX_DIR"/tmp"
    mv $WAYBACK_INDEX_DIR/*.gz $WAYBACK_INDEX_DIR"/tmp"
    mv $WAYBACK_INDEX_DIR/*.loc $WAYBACK_INDEX_DIR"/tmp"
    mv $WAYBACK_INDEX_DIR/*.summary $WAYBACK_INDEX_DIR"/tmp"
    mv $WAYBACK_INDEX_DIR/part-* $WAYBACK_INDEX_DIR"/tmp"
    mv $WAYBACK_INDEX_DIR/*cdxj* $WAYBACK_INDEX_DIR"/tmp"


	echo "Copio i nuovi indici compressi in "$WAYBACK_INDEX_DIR
    cp ./zipnum/* $WAYBACK_INDEX_DIR/.

    cd $HARVEST_DIR
}

function replace_warc_indexes_with_compressed_ones_in_index()
{
	echo ""
    echo "--> Sostituisco i vecchi indici (compressi e non) con i nuovi indici compressi per collezione 'index'"
    cd $INDEX_COMPRESSION_DIR


    if [ $ambiente == "nuovo_esercizio" ]; then
        INDEX_INDEX_DIR=$WAYBACK_HOME_DIR"/index.depositolegale.it/collections/index/indexes"
    else
        INDEX_INDEX_DIR=$WAYBACK_HOME_DIR"/index/collections/index/indexes"
    fi


echo "INDEX_INDEX_DIR="$INDEX_INDEX_DIR


    if [ ! -d $INDEX_INDEX_DIR"/tmp" ]; then
      echo "---> Create directory "$INDEX_INDEX_DIR"/tmp"
      mkdir $INDEX_INDEX_DIR"/tmp"
	fi

	echo "Sposto gli indici vecchi in "$INDEX_INDEX_DIR"/tmp"
    mv $INDEX_INDEX_DIR/*.gz $INDEX_INDEX_DIR"/tmp"
    mv $INDEX_INDEX_DIR/*.loc $INDEX_INDEX_DIR"/tmp"
    mv $INDEX_INDEX_DIR/*.summary $INDEX_INDEX_DIR"/tmp"
    mv $INDEX_INDEX_DIR/part-* $INDEX_INDEX_DIR"/tmp"
    mv $INDEX_INDEX_DIR/*cdxj* $INDEX_INDEX_DIR"/tmp"


	echo "Copio i nuovi indici compressi in "$INDEX_INDEX_DIR
    cp ./zipnum/* $INDEX_INDEX_DIR/.

    cd $HARVEST_DIR
}





function create_warcs_sequencially()
{
    echo "CREATE WARCS SEQUENCIALLY"
    echo "========================="
    # cd $warcs_work_area_dir
    cd $warcs_dir

    echo "Physical destination warcs dir: "$dest_warcs_dir
    # echo "Running $concurrent_warc_jobs CONCURRENT warc jobs for $warcs_parallel_input_file"

        while IFS= read -r seeds_filename
            do
            (
                ((line_ctr++))

                if [[ ${seeds_filename:0:1} == "#" ]] || [[ ${seeds_filename} == "" ]];  then
                    # echo "continue"
                      continue
                fi


               # echo "line_ctr= $line_ctr"
               check_free_disk

               # cd $warcs_work_area_dir

               local fname=$(basename -- "$seeds_filename")
               # local fname="${fname%.*}"


               # if [ "$DEVELOPMENT" == "true" ]; then
               #     local fname="${fname%.*.*}"
               # else
                   local fname="${fname%.*}"
               # fi

# echo "fname=$fname"

echo "wget_ting $seeds_filename"

               # Option --delete-after instructs wget to delete each downloaded file immediately after its download is complete.
               # Option --no-directories prevents wget from leaving behind a useless tree of empty directories.
               #  Certe opzioni sembrano essere ignorate: eg. --no-directories --no-warc-keep-log
               wget_options="--warc-tempdir=. --delete-after --no-directories --no-warc-keep-log --no-check-certificate --user-agent='bncf' --page-requisites"

                # DEBUG
               # wget_options="--warc-tempdir=. --no-warc-keep-log --no-check-certificate --user-agent='bncf' --page-requisites"
# pwd
 # echo "wget $wget_options --input-file=$seeds_filename --output-file=./$fname.log --warc-file=./$fname"
                # if  [[ $fname == *unicatt ]] ; # se finisce in unicatt
                # then
                # SEMBRA FUNZIONARE anche solo con controllo indirizzo IP
                #     echo "ACCESSO controllato a pagine dietro login di UNICATT"
                #
                #     echo "Login. Per prendere la sessione utente"
                #     wget --save-cookies cookies.txt --keep-session-cookies --delete-after --post-data 'user=appsrv.docta.ssows&password=kMcydyT3QhqMhlQE4O1m!' https://login.unicatt.it/iam-fe/sso/login
                #
                #     echo "Accesso a pagina di una tesi. Altrimenti non funziona"
                #     wget -qO- --load-cookies ./cookies.txt http://hdl.handle.net/10280/296 &> /dev/null
                #
                #     # 20/02/2020 Depositiamo direttamente il warc file nella cartella dei warc della wayback machine
                #
                #     wget $wget_options --load-cookies ./cookies.txt --input-file=$seeds_filename --output-file=./$fname.log --warc-file=$dest_warcs_dir/$fname
                # fi

                # 20/02/2020 Depositiamo direttamente il warc file nella cartella dei warc della wayback machine

                # Gestito in fase di estrazione SEEDS if [ $materiale == $MATERIALE_EJOURNAL ]; then
                #     wget_options="${wget_options} --lua-script=$HARVEST_DIR/ojs.lua"
                # fi

# echo "wget_options="$wget_options
                wget $wget_options --input-file=$seeds_filename --output-file=./$fname.log --warc-file=$dest_warcs_dir/$fname
               )
            done < "$warcs_parallel_input_file"

cd $HARVEST_DIR

} # end create_warcs_sequencially












function copy_warcs_and_logs_to_destination_dir_and_remove()
{
    # echo "copy_warcs_to_destination_dir: "$dest_warcs_dir
    echo ""

     while IFS='|' read -r -a array line
     do
        line=${array[0]}
        # Remove whitespaces (empty lines)
        line=`echo $line | xargs`

        if [[ ${line:0:1} == "@" ]]; then # Ignore rest of file
        break
        fi

        # se riga comentata o vuota skip
        if [[ ${line:0:1} == "#" ]] || [[ ${line} == "" ]];  then
             continue
        fi

        # istituto=$(echo "${array[1]}" | cut -f 1 -d '.')
        istituto=${array[1]}
        echo "istituto="$istituto


        # Copiamo il warc.gz
        # ==================

# 
#         if [ $materiale == $MATERIALE_TESI ]; then
#             warc_source_filename=$warcs_dir"/"$harvest_date_materiale"_"$istituto".warc.gz"
#         elif [ $materiale == $MATERIALE_EJOURNAL ]; then
#             warc_source_filename=$warcs_dir"/"$harvest_date_materiale"_"$istituto".warc.gz.viewer"
#         fi

#         warc_dest_filename=$dest_warcs_dir"/"$harvest_date_materiale"_"$istituto".warc.gz"
#         copy_warc_to_destination_dir $warc_source_filename $warc_dest_filename
#         if [[ $? != 0 ]]; then 
#             # echo "Copy failed"
#             return; 
#         fi


        if [ $materiale == $MATERIALE_EJOURNAL ]; then
            root_filename=$harvest_date_materiale"_"$istituto*".warc.gz.viewer"
        else
            root_filename=$harvest_date_materiale"_"$istituto*".warc.gz"
        fi

        # gestione file segmentati e non
        for warc_source_filename in $warcs_dir"/"$root_filename; do

            dest_filename="${warc_source_filename##$warcs_dir/}" # substring removal

        if [ $materiale == $MATERIALE_EJOURNAL ]; then
            dest_filename=${dest_filename::-7} # remove ".viewer"
            echo "dest_filename="$dest_filename
        fi


            warc_dest_filename=$dest_warcs_dir"/"$dest_filename

# echo "warc_source_filename="$warc_source_filename
# echo "dest_filename="$dest_filename


            # echo "Copy '$warc_source_filename' to '$warc_dest_filename'"
            copy_warc_to_destination_dir $warc_source_filename $warc_dest_filename
            if [[ $? != 0 ]]; then 
                echo "Copy '$warc_source_filename' to '$warc_dest_filename'"
                echo "COPY FAILED!!!! STOP"
                exit 1; 
            fi
        done


        if [ $materiale == $MATERIALE_EJOURNAL ]; then
            root_filename=$harvest_date_materiale"_"$istituto*".warc.gz.viewer.md5"
        else
            root_filename=$harvest_date_materiale"_"$istituto*".warc.gz.md5"
        fi
        # gestione file segmentati e non
        for warc_source_filename in $warcs_dir"/"$root_filename; do
            # warc_dest_filename=$dest_warcs_dir"/"$root_filename
            dest_filename="${warc_source_filename##$warcs_dir/}" # substring removal

        if [ $materiale == $MATERIALE_EJOURNAL ]; then
            dest_filename=${dest_filename::-11}".md5" # remove ".viewer"
            echo "dest_filename="$dest_filename
        fi



            warc_dest_filename=$dest_warcs_dir"/"$dest_filename

            echo "Copy '$warc_source_filename' to '$warc_dest_filename'"
            copy_warc_to_destination_dir $warc_source_filename $warc_dest_filename
            if [[ $? != 0 ]]; then 
                echo "Copy '$warc_source_filename' to '$warc_dest_filename'"
                echo "COPY FAILED!!!! STOP"
                exit 1; 
            fi
        done



        # Copiamo il log file del warc
        # ============================
        log_source_filename=$warcs_dir"/"$harvest_date_materiale"_"$istituto".log"
        log_check_pdf_source_filename=$warcs_dir"/"$harvest_date_materiale"_"$istituto".log.check_pdf"

        echo "Copying " $log_source_filename "to " $warcs_log_dir"/."
        cp -p $log_source_filename $warcs_log_dir"/."
        echo "Copying " $log_check_pdf_source_filename "to " $warcs_log_dir"/."
        cp -p $log_check_pdf_source_filename $warcs_log_dir"/." 
        if [ $? -ne 0 ]; then
            echo "ERROR: while copying log file"
        else
 echo "Removing "$log_source_filename
             rm $log_source_filename
 echo "Removing "$fname".log.check_pdf"
            rm $log_check_pdf_source_filename
        fi

     done < "$repositories_file"

} # end copy_warcs_and_logs_to_destination_dir_and_remove

function copy_warc_to_destination_dir ()
{
    echo "copy_warc_to_destination_dir"
    local source_filename=$1
    local dest_filename=$2

    echo "source_filename: " $source_filename
    echo "dest_filename: " $dest_filename

    echo "Make destination file read/write (if present) " $dest_filename
    if [ -f $dest_filename ]; then
        chmod 666 $dest_filename
    fi

    echo "Copying $source_filename to $dest_warcs_dir"
    cp -p $source_filename $dest_filename
    if [ $? -ne 0 ]; then
        echo "ERROR: while copying warc file!!! STOP COPYING"
        return 1 
    else
        echo "Removing "$source_filename
        rm $source_filename
        echo "Make destination file read only: " $dest_filename
        chmod 444 $dest_filename
    fi
    return 0 
} # End copy_warc_to_destination_dir



# function make_dest_warcs_read_write()
# {
#     echo "make_dest_warcs_read_write: "$dest_warcs_dir
#     chmod 666 $dest_warcs_dir/*gz
# }

# function make_dest_warcs_read_only()
# {
#     echo "make_dest_warcs_read_only: "$dest_warcs_dir
#     chmod 444 $dest_warcs_dir/*gz
# }




function check_pdf_download()
{
    echo "Check pdf download"

    while IFS='|' read -r -a array line
    do
        line=${array[0]}

        # Remove whitespaces (empty lines)
        line=`echo $line | xargs`

        if [[ ${line:0:1} == "@" ]]; then # Ignore rest of file
            break
        fi

        if [[ ${line:0:1} == "#" ]] || [[ "$line" == "" ]];     then
            continue
        fi


        log_file=$warcs_dir/$harvest_date_materiale"_"${array[1]}".log"
        echo "check " $log_file


        grep -B 1 "^Saving to: ‘.*pdf’" $log_file |  grep -A 1 "text\/html" > $log_file".check_pdf"




# -A NUM, --after-context=NUM
# -B NUM, --before-context=NUM


    done < "$repositories_file"
}



function create_warcs_to_index_list()
{

    # echo "Creiamo la lista dei warc da indicizzare: "$dest_warcs_dir"/warcs.lst"
    # ls -1rt $dest_warcs_dir/*warc.gz > $dest_warcs_dir"/warcs.lst"

    warc_list="$dest_warcs_dir"/warcs.lst
    echo "Creiamo la lista dei warc da indicizzare: "$warc_list

   if [[ -f $warc_list ]]; then
        echo "Remove $warc_list"
        rm $warc_list
    fi 

    while IFS='|' read -r -a array line
    do
        line=${array[0]}

        # Remove whitespaces (empty lines)
        line=`echo $line | xargs`

        if [[ ${line:0:1} == "@" ]]; then # Ignore rest of file
            break
        fi

        if [[ ${line:0:1} == "#" ]] || [[ "$line" == "" ]];     then
            continue
        fi

        wgz=$dest_warcs_dir/$harvest_date_materiale"_"${array[1]}".warc.gz" 

        echo "adding $wgz"
        echo $wgz $log_file >> $warc_list
    done < "$repositories_file"
}




function check_for_harvest_mismatch_istituto()
{
local fname=$1

    mismatch=0;

    # for seeds_to_harvest_filename in $seeds_dir/*.seeds
    # for log_filename in $warcs_log_dir/*.log
    # do
    #     fname=$(basename -- "$log_filename")
    #     fname="${fname%.*}"

# echo "fname="$fname
        seeds_to_harvest_filename=$seeds_dir/$fname.seeds
        # echo "seeds_to_harvest_filename="$seeds_to_harvest_filename
# continue
        echo "$seeds_to_harvest_filename"
        # seeds_to_harvest=$(cat $seeds_to_harvest_filename | wc -l)
        seeds_to_harvest=$(cat $seeds_to_harvest_filename | sed '/^\s*#/d;/^\s*$/d' | wc -l) # Exclude empty lines (also  commented lines


        seeds_in_warc=0
        seeds_not_in_warc=0
        #  Contiamo i seed scaricati
        siw=$warcs_log_dir/$fname.log.seeds_in_warc
        if [[ -f $siw ]]; then
            seeds_in_warc=$(cat $siw | wc -l)
        fi
        sniw=$warcs_log_dir/$fname.log.seeds_not_in_warc
        if [[ -f $sniw ]]; then
            seeds_not_in_warc=$(cat $sniw | wc -l)
        fi
        tot_seeds_from_wget=$((seeds_in_warc + seeds_not_in_warc))
        if [[ "$seeds_to_harvest" -gt "$tot_seeds_from_wget" ]]; then
            echo "$seeds_to_harvest seeds to harvest in $seeds_to_harvest_filename"
            echo "$tot_seeds_from_wget seed harvested in $seeds_to_harvest_filename (see .missing)"
            let "mismatch=mismatch+1"
        fi
    # done

    # if [[ $mismatch < 1 ]]; then
    #     echo "GREAT!!! Nessun mismatch tra URL(seed) da scaricare e scaricate"
    # else
    #     echo "CHECK!!! $mismatch siti miscmath tra URL(seed) da scaricare e scaricate"
    # fi

    if [[ $mismatch > 0 ]]; then
        echo "CHECK!!! $mismatch siti miscmath tra URL(seed) da scaricare e scaricate"
    fi

} # end check_for_harvest_mismatch_istituto



function check_for_harvest_mismatch()
{
    echo "CHECK FOR HARVEST MISMATCH"
    echo "=========================="


    DONE=false
    until $DONE; do
        IFS='|' read -r -a array line  || DONE=true

        line=${array[0]}

        # Remove whitespaces (empty lines)
        line=`echo $line | xargs`

        if [[ ${line:0:1} == "@" ]]; then # Ignore rest of file
            break
        fi

        # se riga comentata o vuota skip
        if [[ ${line:0:1} == "#" ]] || [[ ${line} == "" ]];  then
              continue
         fi
        local istituto=${array[1]}

        # echo "Working on: " $istituto

        if [ $materiale == $MATERIALE_TESI ]; then
            # Prepariamop le ricevute in formato excel per TESI
    
            check_for_harvest_mismatch_istituto $harvest_date_materiale"_"$istituto

        elif [ $materiale == $MATERIALE_EJOURNAL ]; then
            # Prepariamop le ricevute in formato excel per E-JOURNALS
            check_for_harvest_mismatch_istituto $harvest_date_materiale"_"$istituto
        fi

    done < "$repositories_file"
} # end check_for_harvest_mismatch




# CREATE WARCS MD5 fo checking when storing in S3 storage
function create_warcs_md5()
{

    echo "CREATE WARC'S MD5"
    echo "================="


     while IFS='|' read -r -a array line
     do
           line=${array[0]}

        # Remove whitespaces (empty lines)
        line=`echo $line | xargs`

          if [[ ${line:0:1} == "@" ]]; then # Ignore rest of file
            break
          fi

           # se riga comentata o vuota skip
           if [[ ${line:0:1} == "#" ]] || [[ ${line} == "" ]];  then
                 continue
            fi

        # istituto=$(echo "${array[1]}" | cut -f 1 -d '.')
        istituto=${array[1]}

#       echo "istituto="$istituto

        # if [ $materiale == $MATERIALE_EJOURNAL ]; then
        #     filename=$warcs_dir"/"$harvest_date_materiale"_"$istituto".warc.gz.viewer"
        # else
        #     filename=$warcs_dir"/"$harvest_date_materiale"_"$istituto".warc.gz"
        # fi

        # md5_filename=$filename".md5"

        # echo "Do md5 for " $filename 
        # md5sum $filename > $md5_filename 



        if [ $materiale == $MATERIALE_EJOURNAL ]; then
            root_filename=$harvest_date_materiale"_"$istituto*".warc.gz.viewer"
        else
            root_filename=$harvest_date_materiale"_"$istituto*".warc.gz"
        fi

        # gestione file segmentati e non
        for filename in $warcs_dir"/"$root_filename; do
        md5_filename=$filename".md5"

        echo "Do md5 for " $filename 
        md5sum $filename > $md5_filename 
            
        done






     done < "$repositories_file"

} # end prepare_warcs_md5



# CREATE WARCS MD5 fo checking when storing in S3 storage
function create_dest_warcs_md5()
{

    echo "CREATE WARC'S MD5"
    echo "================="


     while IFS='|' read -r -a array line
     do
           line=${array[0]}

        # Remove whitespaces (empty lines)
        line=`echo $line | xargs`

          if [[ ${line:0:1} == "@" ]]; then # Ignore rest of file
            break
          fi

           # se riga comentata o vuota skip
           if [[ ${line:0:1} == "#" ]] || [[ ${line} == "" ]];  then
                 continue
            fi

        istituto=$(echo "${array[1]}" | cut -f 1 -d '.')
echo "create md5 for istituto="$istituto
        filename=$dest_warcs_dir"/"$harvest_date_materiale"_"$istituto".warc.gz"
        md5_filename=$filename".md5"

        echo "Do md5 for " $filename 
        md5sum $filename > $md5_filename 

     done < "$repositories_file"

} # end create_dest_warcs_md5





#
# wb-manager is a command line tool for managing common collection operations.
#     positional arguments:
#       {init,list,add,reindex,index,metadata,template,cdx-convert,autoindex}
#         init                Init new collection, create all collection directories
#         list                List Collections
#         add                 Copy ARCS/WARCS to collection directory and reindex
#         reindex             Re-Index entire collection
#         index               Index specified ARC/WARC files in the collection
#         metadata            Set Metadata
#         template            Add default html template for customization
#         cdx-convert         Convert any existing archive indexes to new json format
#         autoindex           Automatically index any change archive files
#
#     optional arguments:
#       -h, --help            show this help message and exit
#
#   - inizializzazione di una collezione chiamata my-web-archive
#      - wb-manager init web-archive
#      - wb-manager reindex collections/web-archive
#
#   wayback   - starts a web server that provides the access to web archives (dalla cartella dove stanno le collezioni).



function index_warcs()
{
    echo "--> INDICIZZA WARCS IN WAYBACK $dest_warcs_dir"
    echo "--> WAYBACK_INDEX_DIR = $WAYBACK_INDEX_DIR"

    # Rimozione di index.cdxj
    printf "\n-> Rimuovo vecchio indice: "$WAYBACK_INDEX_DIR"/index.cdxj\n\n"
    if [[ -f $WAYBACK_INDEX_DIR"/index.cdxj" ]]; then
        rm $WAYBACK_INDEX_DIR"/index.cdxj"
    fi

    cd $WAYBACK_DIR

     while IFS='|' read -r -a array line
     do
           line=${array[0]}

        # Remove whitespaces (empty lines)
        line=`echo $line | xargs -0`

          if [[ ${line:0:1} == "@" ]]; then # Ignore rest of file
            break
          fi

           # se riga comentata o vuota skip
           if [[ ${line:0:1} == "#" ]] || [[ ${line} == "" ]];  then
                 continue
            fi

        # istituto=$(echo "${array[1]}" | cut -f 1 -d '.')
        istituto=${array[1]}

        # filename=$dest_warcs_dir"/"$harvest_date_materiale"_"$istituto".warc.gz"
        
        root_filename=$harvest_date_materiale"_"$istituto-*".warc.gz"

        # 22/12/2020 Gstione indexing compresi warcs segmentati
        for filename in $dest_warcs_dir"/"$root_filename; do
            echo "Indexing "$filename

            $WB_MANAGER_DIR"wb-manager" index $WAYBACK_COLLECTION_NAME $filename

            local fname=$(basename -- "$filename")

           # local fname="${fname%.*}"
            cdxj_name="${fname%.*.*}.cdxj"

            echo "cdxj_name= "$cdxj_name
            echo "Rinominiamo " $WAYBACK_INDEX_DIR"/index.cdxj in" $WAYBACK_INDEX_DIR"/"$cdxj_name
            mv $WAYBACK_INDEX_DIR"/index.cdxj" $WAYBACK_INDEX_DIR"/"$cdxj_name
            
        done

        # Insex senza segmentazione
        # echo "Indexing "$filename
        # $WB_MANAGER_DIR"wb-manager" index $WAYBACK_COLLECTION_NAME $filename

        # echo "Rinominiamo " $WAYBACK_INDEX_DIR"/index.cdxj in" $WAYBACK_INDEX_DIR"/"$istituto".cdxj"
        # mv $WAYBACK_INDEX_DIR"/index.cdxj" $WAYBACK_INDEX_DIR"/"$istituto".cdxj"

     done < $HARVEST_DIR"/"$repositories_file
    cd $HARVEST_DIR
} # end index_warcs


# Split huge warcx.gz in smaller ones
function split_warcs_test()
{
    echo "split warcs"

    echo "Copiamo i .py in scripts/."
    cp ~/python_venvs/s3_venv/workspace/*py scripts/.

    echo "Do the splitting"

    istituto=lumsa
    warc_file="/home/argentino/tmp/warcs/2020_11_11_tesi_$istituto.warc.gz"
    blocks_file="/home/argentino/tmp/warcs/members/2020_11_11_tesi_lumsa.warc.gz.blocks"
    members_dir="/home/argentino/tmp/warcs/members"
    block_size=1000000

    # python3 scripts/split_warc.py $warc_file $members_dir $block_size > $blocks_file

    # !!!!! CONTROLLARE nella cartella dei membri con mc che il singolo record ad inizio di un blocco sia corretto (valido .gz)
    echo "Do the extraction"
     while IFS=' ' read -r -a array line
     do
        line=${array[0]}
        # Remove whitespaces (empty lines)
        line=`echo $line | xargs`

          if [[ ${line:0:1} == "@" ]]; then # Ignore rest of file
            break
          fi

           # se riga comentata o vuota skip
           if [[ ${line:0:1} == "#" ]] || [[ ${line} == "" ]];  then
                 continue
            fi
        block_num=${array[1]}
        from_pos=${array[3]}
        block_size=${array[7]}

        # sprintf
        warc_block_out=$(printf '/home/argentino/tmp/warcs/members/2020_11_11_tesi_%s_%05d.warc.gz' "$istituto" "$block_num") 
        # echo "Extract block: $block_num from offset $from_pos, length $block_size to $warc_block_out"
        python3 scripts/extract_binary.py $warc_file $warc_block_out $from_pos $block_size
        # break
     done < $blocks_file
    # !!!!! CONTROLLARE nella cartella dei membri con mc che il blocchi siano validi .gz)
} # end split_warcs_test




function find_warc_offsets()
{
    local istituto=$1
    local members_dir=$2
    local warc_file=$3
    
    echo "Find offsets for: " $istituto

        echo "SPLIT warc.gz for "$istituto



        if [ ! -d $members_dir ]; then
            echo "---> Create directory "$members_dir
            mkdir $members_dir
            if [[ $? != 0 ]]; then 
                # echo "Create dir failed"
                return; 
            fi
        fi

        if [ $ambiente == "sviluppo" ]; then
            echo "Copiamo i .py in scripts/."
            cp ~/python_venvs/s3_venv/workspace/*py scripts/.
        fi


        echo "Find splittable position (start of new .gz record within warc.gz)"
   

        # blocks_file="/home/argentino/tmp/warcs/members/2020_11_11_tesi_lumsa.warc.gz.blocks"
        blocks_file=$members_dir"/"$harvest_date_materiale"_"$istituto".warc.gz.blocks"

        python3 scripts/find_warc_offsets.py $warc_file $members_dir $block_size > $blocks_file

        echo "Vedi $blocks_file"
        # !!!!! CONTROLLARE nella cartella dei membri con mc che il singolo record ad inizio di un blocco sia corretto (valido .gz)

} # end find_warc_offsets()
 


function extract_warc_blocks()
{
    local istituto=$1
    local members_dir=$2
    local warc_file=$3

    blocks_file=$members_dir"/"$harvest_date_materiale"_"$istituto".warc.gz.blocks"

    echo "Do the blocks extraction"
     while IFS=' ' read -r -a array line
     do
        line=${array[0]}

        # Remove whitespaces (empty lines)
        line=`echo $line | xargs`

          if [[ ${line:0:1} == "@" ]]; then # Ignore rest of file
            break
          fi

           # se riga comentata o vuota skip
           if [[ ${line:0:1} == "#" ]] || [[ ${line} == "" ]];  then
                 continue
            fi
        
        block_num=${array[1]}
        from_pos=${array[3]}
        block_size=${array[7]}

        # sprintf
        warc_block_out=$(printf '%s/%s_%s-%04d.warc.gz' $members_dir $harvest_date_materiale $istituto $block_num) 
        # echo "Extract block: $block_num from offset $from_pos, length $block_size to $warc_block_out"

        python3 scripts/extract_binary.py $warc_file $warc_block_out $from_pos $block_size

        
        # !!!!! CONTROLLARE nella cartella dei membri se i warc gz sono ok)

     done < $blocks_file

} # End extract_warc_blocks


# Split huge warcx.gz in smaller ones
function split_warcs()
{
    echo "SPLIT WARC"
    echo "=========="

    # Prova con un file piccolo
    block_size=1000000

    while IFS='|' read -r -a array line
    do
        line=${array[0]}

        # Remove whitespaces (empty lines)
        line=`echo $line | xargs`

        if [[ ${line:0:1} == "@" ]]; then # Ignore rest of file
            break
        fi

        # se riga comentata o vuota skip
        if [[ ${line:0:1} == "#" ]] || [[ ${line} == "" ]];  then
            continue
        fi

        istituto=$(echo "${array[1]}" | cut -f 1 -d '.')

        warc_file=$dest_warcs_dir"/"$harvest_date_materiale"_"$istituto".warc.gz"

        # Create members_dir if not present
        members_dir=$dest_warcs_dir"/"$harvest_date_materiale"_"$istituto"_members"

        find_warc_offsets $istituto $members_dir $warc_file

        extract_warc_blocks $istituto $members_dir $warc_file

        echo "Create md5 checksum on member files"
        for filename in $members_dir/*warc.gz; do
            echo "do md5 for: " $filename
            md5sum $filename > $filename.md5
        done
     
        # SWAP dei warcs
        echo "Sposto warc splittati nella cartella dei warc"
        mv $members_dir/*warc.gz $members_dir/../.
        mv $members_dir/*.md5 $members_dir/../.

        echo "Sposto il warc.gz originale nella cartella dei membri (da cancellare a mano)"
        mv $warc_file $members_dir/.

    done < "$repositories_file"
} # end split_warcs



function change_pdf_viewer_url()
    {
    echo "CHANGE PDF VIEWER URL FOR E_JOURNALS"
    echo "====================================="


     while IFS='|' read -r -a array line
     do
           line=${array[0]}

        # Remove whitespaces (empty lines)
        line=`echo $line | xargs`

          if [[ ${line:0:1} == "@" ]]; then # Ignore rest of file
            break
          fi

           # se riga comentata o vuota skip
           if [[ ${line:0:1} == "#" ]] || [[ ${line} == "" ]];  then
                 continue
            fi

        # istituto=$(echo "${array[1]}" | cut -f 1 -d '.')
        local istituto=${array[1]}

echo "istituto="$istituto

        # warc_gz_in=$warcs_dir"/"$harvest_date_materiale"_"$istituto".warc.gz"
        # warc_gz_out=$warc_gz_in".viewer"
        # if [ ! -f $warc_gz_in ]; then
        #     # Abbiamo dei file segmentati?
        #     echo "Warc sorgente mancante: " $warc_gz_in
        #     continue
        # else
        #     echo "Change viewer url for "$warc_gz_in
        #     python3 -m warcat ejviewer $warc_gz_in --output $warc_gz_out --gzip 
        # fi


        # 15/03/2021 Gstione viewer warcs segmentati e non
        root_filename=$harvest_date_materiale"_"$istituto*".warc.gz"
        for filename in $warcs_dir"/"$root_filename; do
            
            echo "Change viewer url for "$filename
            python3 -m warcat ejviewer $filename --output $filename".viewer" --gzip 
        done


        # -s FILE - True if the FILE exists and has nonzero size.
        # if [[ ! -s $warc_gz_out ]]; then
        #     echo "No valid warcat file. DO NOT rename"
        #     continue
        # else
        #    echo "Rename $warc_gz_in to "$warc_gz_in".org"
        #     mv $warc_gz_in $warc_gz_in".org"
        #    echo "Rename $warc_gz_out to $warc_gz_in"
        #     mv $warc_gz_out $warc_gz_in
        # fi


     done < "$repositories_file"

 } # end change_pdf_viewer_url

# =============================================================================
# OBSOLETE
# Solo per file molto grandii > 15GB (split e md5 manuale per il momento)
# upload_split_warcs_to_s3
#
# -------------------------------------
# !!!! Caricamento warcs da harvest precedenti fino al 10/2018
# 
# ONCE ONLY!!!
# -- prepare_etd_warcs_list_to_upload()
# from_line=1
# to_line=1
# multipart_mode=false
# upload_etd_warcs_to_S3    $from_line $to_line $multipart_mode
#
# prepare_harvest_record_storico    1   5
# prepare_harvest_record_cdx_storico
# scripts/DbUpdateInsertS3.sh

# =============================================================================


